---
title: 4、第二周总结-01
tags: 
notebook: 第六个月总结笔记
---


# 第一天，requests框架
    总体总结除了session以外其他都是传个值就可以了
### 使用requests框架
    pip install requests
    1、import requests
    2、requests.get(url连接)

    需要的参数有：
        url = 'https://movie.douban.com/subject_search' 需要填写get参数
        params = {} 这个是？号后面的get参数可以不用字符串拼接
        data = {} post请求不需要转化，直接填字典就行
        json
        headers = {} 请求头
        cookies = {'bid':'yTyQEkmXdBE',}
        files = [{'file':open('postdata.txt','rb')},{}]
        auth = (user,passsword)
        timeout = 3
        allow_redirects = false true
        proxies = {'http':'1270.0.0.1:8080'} 代理
        verify = false 可以忽略未知授权
        stream = 
        cert = 
### requests返回对象的一些方法和属性
    response.status_code    状态码
    response.text           返回是解码后的字符串
    response.content        返回的是二进制数据
    response.headers        获取响应头
    response.headers['Connection']  获取响应头的某一个参数
    response.cookies        返回的是一个RequestsCookieJar对象，里面有cookie参数
    response.json()         在内部直接将json字符串，转换成了python数据类型的对象
### request对象的方法
    request.get()
    request.post()
    request.session()
    cookie_dict = requests.utils.dict_from_cookiejar(response.cookies) 可以把cookie对象转换成字典类型

### post请求
    response = requests.post('https://httpbin.org/post',data=from_data)

### 代理
    requests.get(url,proxies=proxies)

### cookie的使用
    response = requests.get(url,cookies=cookies)
### 维持一个回话，使用session对象
    构造一个session对象，来维持会话，他会保存cookies，然后下次发起请求的时候会携带cookie
    session = requests.session()
    response = session.post('http://www.renren.com/PLogin.do',data=from_data,headers=headers)
    response = session.get('http://www.renren.com/965722397/profile')
### 文件上传
    response = requests.post('https://httpbin.org/post',files=files)
###  有时候我们使用response.text也会出现乱码的情况，(utf-8\GBK)
    response.encoding = 'utf-8' 
### 上传图片
    multiple_files = [
        ('images', ('foo.jpg', open('foo.jpg', 'rb'), 'image/jpg')),
        ]
    r = requests.post(url, files=multiple_files)
### 返回json数据时
    response = requests.get(url,headers=headers)
    response.encoding = 'utf-8'
    print(response.json())
    

### 使用json模块
    json.load   是将本地文件中的json字符串，转换为python
    json.dump   可以将python对象转为json字符串，并存储
    json.loads  可以将json字符串转为python对象
    json.dumps  可以将python对象转为json字符串

    data = json.loads(response.text)
    data = json.load(open('json_data.json','r'))

    json.dump(data,open('json_data.json','w'),ensure_ascii=False) ensure_ascii等于false是不使用ascii码
    json_str = json.dumps(subdata,ensure_ascii=False)
### 注意事项：
    1.json的嵌套数据必须是object（dict）和数组（list）
    2.json数据中的数据引用必须使用双引号
### xpath的使用
    要使用xpath，首先要倒入lxml库：lxml是一个解析器，能够解析xml/html文档
    要使用它，首先要pip3 install lxml

    from lxml import etree
    html = etree.HTML(response.text) 1.首先使用etree将获取到的html文本转换成htmldom（文档模型对象）
    novel_list = html.xpath('//div[@class="right-book-list"]/ul/li')

    nodename： 获取所有符合节点名称的节点（标签）
    / ：从根节点开始获取
    // ：无论节点在任何位置，使用//都能将其匹配出来。
    . ：从当前节点获取
    @ ：用来获取属性值
    text():表示获取标签文本

    图片链接
    image_url = li.xpath('./div[@class="book-img"]//img/@src')[0]
    小说的标题
    title = li.xpath('./div[@class="book-info"]/h3/a/text()')[0]
    作者名称
    author = li.xpath('./div[@class="book-info"]/h4/a/text()')[0]
    标签
    tags = ','.join(li.xpath('.//p[@class="tag"]/span/text()'))
    描述
    desc = li.xpath('.//p[@class="intro"]/text()')[0]

    总结就两点：
        转换成文档模型对象
        取数据