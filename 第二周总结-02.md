---
title: 5、第二周总结-02
tags: 
notebook: 第六个月总结笔记
---


# 第二天，selenium自动化测试工具
    pip3 install selenium
    from selenium import webdriver


    1、 opt = webdriver.ChromeOptions()
        opt.set_headless()
    
    2、 dirver = webdriver.Chrome(options=opt,executable_path='/Users/ljh/Desktop/chromedriver')

    3、 dirver.get('https://movie.douban.com/subject_search?search_text=%E6%88%90%E9%BE%99&cat=1002')

        with open('page.html','w') as f:
            f.write(dirver.page_source)

    4、 dirver.close()

        
    
### selenium对象的方法：
    dirver.page_source                   html文本
    dirver.save_screenshot('baidu.png')  截图
    dirver.find_element_by_id('节点id').send_keys('搜索内容') 
    dirver.find_element_by_id('su').click()  点击按钮
    dirver.implicitly_wait(10)               隐士等待
    dirver.back()                            后退
    dirver.forward()                         前进
    dirver.refresh()                         刷新当前页面
    dirver.get_cookies()                     获取cookie值
    dirver.close()                           退出浏览器

### pyrequety用法
    from pyquery import PyQuery as pq
    1、pq = pq(response.text)


    pq.html()
    pq('p')
    pq.find('p')
    pq.items('p')
    pq.filter('.Card.HomeMainItem')

    for div in list.items():
        print(type(div))
        from_title = div('.Popover div').eq(0).text()


### beautfitsoup
    pip3 install beautifulsoup4 安装
    from bs4 import BeautifulSoup

    soup = BeautifulSoup(response.text,'html5lib')
    
    总结：
    以下三个都是解析器：
    html5lib
    lxml
    html.parser

    beautifulsoup：也是对html/xml的解析，作用是为了从html/xml解析和提取数据
    首先构造一个soup对象
    soup.标签
    soup.标签.string
    soup.标签.name
    soup.标签.attrs
    标准的格式输出一个文本perttify()
    soup.find_all(标签名、text、属性值)
    soup.find_all(class_="") #class要加下滑线，不然会冲突
    soup.find_all(id="")
    soup.find_all('标签名')
    soup.find_all(attrs=attrs{'属性名称':'属性值'})
    soup.find_all(text="要获取的文本信息")

    css语法
    . 表示类（class）
    # 表示id（id）
    组合使用：
    p.class #item li

    获取标签的文本信息
    标签.get_text()
    标签.string

    获取属性
    标签.attrs

    标签.attrs['href']
    标签['href']
    标签.get('href')

